{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "import os,glob,sys,requests\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processed_url.txt :  contain the list of downloaded files \n",
    "### failed_url.txt  :    contain the list of files:   failed to download  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path=\"/home/ubuntu/projects/continual/dataset/\"\n",
    "def download_file(url,cls):\n",
    "    \"\"\"\n",
    "    @ url:  url for download\n",
    "    @ url image class \n",
    "    \"\"\"\n",
    "    try:\n",
    "        local_filename = url.split('/')[-1]\n",
    "        # NOTE the stream=True parameter below\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            save_path_cls=save_path+cls\n",
    "            print(save_path_cls)\n",
    "            Path(save_path_cls).mkdir(parents=True, exist_ok=True)\n",
    "            with open(save_path_cls+\"/\"+local_filename, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192): \n",
    "                    if chunk: # filter out keep-alive new chunks\n",
    "                        f.write(chunk)\n",
    "                        # f.flush()\n",
    "        return [url,cls]\n",
    "    except:\n",
    "        return [None,url,cls]\n",
    "\n",
    "    \n",
    "with open(\"vis10cat.txt\", \"r\") as f:\n",
    "    data=f.readlines()\n",
    "    \n",
    "    wait_for = []\n",
    "    with futures.ThreadPoolExecutor(max_workers=2) as ex:\n",
    "\n",
    "        for d in data:\n",
    "            url=d.split(\"\\t\")[-1].split(\"\\n\")[0]\n",
    "            cls=d.split(\"\\t\")[0]\n",
    "            w=ex.submit(download_file, url,cls)\n",
    "            wait_for.append(w)\n",
    "\n",
    "    f1 = open(\"processed_url.txt\", \"a\")\n",
    "    f2 = open(\"failed_url.txt\", \"a\")\n",
    "\n",
    "    for f in futures.as_completed(wait_for):\n",
    "        if f.result()[0]:\n",
    "            f1.write(f.result()[1]+\"\\t\"+f.result()[0]+\"\\n\")\n",
    "        else:\n",
    "            f2.write(f.result()[2]+\"\\t\"+f.result()[1]+\"\\n\")\n",
    "        print('main: result: {}'.format(f.result()[0]))\n",
    "    f1.close()\n",
    "    f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing currept files and git to png converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import cv2,glob,os\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "\n",
    "path_f=\"/home/ubuntu/projects/continual/dataset/final_clean/\"\n",
    "\n",
    "def processImage(infile):\n",
    "    \"\"\"\n",
    "    @infile : input image path\n",
    "    @ return :  converted png file path\n",
    "    \"\"\"\n",
    "    try:\n",
    "        im = Image.open(infile)\n",
    "    except IOError:\n",
    "        print( \"Cant load\", infile)\n",
    "        return None\n",
    "    i = 0\n",
    "    mypalette = im.getpalette()\n",
    "    if mypalette is None:\n",
    "        return None\n",
    "    fname=infile.split(\"/\")[-2]\n",
    "    save_path_cls=path_f+fname+'/'\n",
    "    Path(save_path_cls).mkdir(parents=True, exist_ok=True)\n",
    "    img_name=infile.split(\".\")[-2].split(\"/\")[-1]+str(i)\n",
    "\n",
    "    f_save_p=save_path_cls+img_name+'.png'\n",
    "\n",
    "    try:\n",
    "        while 1:\n",
    "            \n",
    "            im.putpalette(mypalette)\n",
    "            new_im = Image.new(\"RGBA\", im.size)\n",
    "            new_im.paste(im)\n",
    "            new_im.save(f_save_p)\n",
    "\n",
    "            i += 1\n",
    "            im.seek(im.tell() + 1)\n",
    "\n",
    "    except EOFError:\n",
    "        return f_save_p\n",
    "        \n",
    "    return f_save_p\n",
    "\n",
    "\n",
    "ims=glob.glob(\"dataset/Table/*\")\n",
    "for img in ims:\n",
    "    fname=img.split(\"/\")[-2]\n",
    "    save_path_cls=path_f+fname+'/'\n",
    "    Path(save_path_cls).mkdir(parents=True, exist_ok=True)\n",
    "    filename=img.split(\"/\")[-1]\n",
    "    if img.split('.')[-1] == \"gif\":\n",
    "        if os.path.isfile(img):\n",
    "            dst=processImage(img)  # Convert gif to png file \n",
    "            if dst:\n",
    "                img_o = cv2.imread(dst)\n",
    "                if img is  None:\n",
    "                    break\n",
    "                    os.remove(dst)\n",
    "                else:\n",
    "                    print(dst,img) \n",
    "        \n",
    "    else:\n",
    "        img_o = cv2.imread(img)\n",
    "        if img_o is not None:\n",
    "            print(img_o.shape)\n",
    "            #copyfile(img, save_path_cls+filename) # Copy file to destination\n",
    "        else:\n",
    "            print(img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "almondaiEnv",
   "language": "python",
   "name": "almondaienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
